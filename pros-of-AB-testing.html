<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <title>The pros of the A/B testing method</title>
        <link rel="stylesheet" href="/theme/css/main.css" />

        <!--[if IE]>
            <script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">And yet it moves! </a></h1>
                <nav><ul>
                    <li class="active"><a href="/category/data-processing.html">Data processing</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/pros-of-AB-testing.html" rel="bookmark"
           title="Permalink to The pros of the A/B testing method">The pros of the A/B testing&nbsp;method</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2016-05-15T12:26:00+01:00">
                Published: dim. 15 mai 2016
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/gael.html">Gaël</a>
        </address>
<p>In <a href="/category/data-processing.html">Data processing</a>.</p>

</footer><!-- /.post-info -->      <p><center><img alt="" src="/images/dab.gif"/></center></p>
<p>In order to bring some nuances and perspective into the discussion
(a.k.a. <em>unsupported claims smashing</em>&trade;), this post is
dedicated to showing what A/B testing is good at and how it compares to the
multi-armed bandit&nbsp;strategy.</p>
<h1 id="ab-testing-is-more-powerful-than-mab-testing">A/B testing is more powerful than <span class="caps">MAB</span>&nbsp;testing</h1>
<p>When a (statistical) test is applied to data, it answers the question for which
it was designed with a given <em>level of significance</em> and <em>power</em> (the two
components of what we could improperly call &ldquo;level of confidence&rdquo; for&nbsp;simplicity):</p>
<ul>
<li>
<p>The <em>level of significance</em> is the probability of correctly concluding 
    that the variants (<img alt="the orange" src="/images/orange_btn.svg"/>
    and <img alt="the green button" src="/images/green_btn.svg"/> here) <em>have <strong>no</strong>
    significant impact</em> on the click-through&nbsp;rate.</p>
</li>
<li>
<p>The <em>power</em> is the probability of correctly concluding that the variants
    <strong>have</strong> <em>a significant impact</em> on the click-through&nbsp;rate.</p>
</li>
</ul>
<p>The power is the most important estimator of confidence in our case:
if we see a difference, we would like to know if it is significant.
So we modelled<todo: link=""> the whole process and estimated the power in each
method at a given level of significance and for different sample&nbsp;sizes.</todo:></p>
<p><img alt="If you can't see the figure, please try another web browser which supports
SVG images" src="/images/power_vs_sample_size.svg"/></p>
<p>It appears clearly that A/B testing reaches higher (and better) powers at far
smaller sample sizes: it typically requires sample sizes <em>5 times</em> smaller
than with <span class="caps">MAB</span>!</p>
<p><em>Why is that?</em> As we claimed above when presenting the A/B testing method, it
is generally more efficient to provide each variant as often than to favour
one. A/B testing is better here and we didn&rsquo;t even have to look for a
convoluted setup: this is valid for all the setups we&nbsp;tried!</p>
<h1 id="ab-testing-is-correct-more-often-at-small-sample-sizes">A/B testing is correct more often at small sample&nbsp;sizes</h1>
<p>There are cases however where no test is used. This is equivalent to saying
that you choose a level of significance of <span class="math">\(0\%\)</span>. Yet that does not mean that
the power would reach <span class="math">\(100\%\)</span> (in this case, the power is equivalent to how
often the seemingly best-performing variant is really the best&nbsp;performer).</p>
<p>As it turned out, even in
that case, the A/B data-gathering strategy does provide better&nbsp;results:</p>
<p><img alt="If you can't see the figure, please try another web browser which supports
SVG images" src="/images/correct_vs_sample_size.svg"/></p>
<p>In this example, the A/B framework again provide better results at smaller
sample sizes. For instance, the A/B framework only requires <span class="math">\(300\)</span> trials
to be correct in <span class="math">\(9\)</span> campaigns out of <span class="math">\(10\)</span>. To provide the <em>same</em> guarantee,
the <span class="caps">MAB</span> strategy would require <span class="math">\(600\)</span> trials: twice as&nbsp;many!</p>
<p>This can be explained the same way as above: providing each website variant as
often to the visitors to get the best-performing variant is more&nbsp;efficient.</p>
<h1 id="ab-testing-provides-more-accurate-estimations-of-the-differences">A/B testing provides more accurate estimations of the&nbsp;differences</h1>
<p>A correct estimation of the differences in click-through rates is important:
it is required in methods relying on its quantifications (e.g. multivariate
analysis) but also to actually determine which variant performs&nbsp;better:
</p>
<div class="math">$$a &gt; b$$</div>
<p> is equivalent&nbsp;to </p>
<div class="math">$$a - b &gt; 0\text{.}$$</div>
<p>I estimated the difference in click-through rates (denoted <span class="math">\(P(O|B) - P(O|A)\)</span> 
in the figure &mdash; see why here<todo: link="">) in the same setup as above and
obtained the following&nbsp;figure:</todo:></p>
<p><img alt="If you can't see the figure, please try another web browser which supports
SVG images" src="/images/difference_vs_sample_size.svg"/></p>
<p>We can clearly see that the A/B testing data gathering method converges toward
the expected value of <span class="math">\(5\%\)</span> much faster than the <span class="caps">MAB</span> strategy. Worse, that
remaining difference, though small, actually goes on and on for a very long&nbsp;time.</p>
<h1 id="summary-what-is-ab-testing-good-at">Summary: what is A/B testing good&nbsp;at?</h1>
<p>These results illustrated what it means for A/B testing to answer the question:
<em>Is there a&nbsp;difference?</em></p>
<ul>
<li>Its data-gathering scheme is efficient: it provide a very high power in the
    contingency tests, it leads to correct results more often at lower sample
    rates than with the <span class="caps">MAB</span>&nbsp;strategy.</li>
<li>It makes use of the contingency test to actually answer that question at a
    given &ldquo;level of confidence&rdquo; (significance and power). It is also used to
    determine what the sample size should&nbsp;be.</li>
<li>It also generally provides more precise and more accurate estimates of the 
    actual difference in click-through&nbsp;rates.</li>
</ul>
<p>Beyond invalidating the most outrageous claims of the original blog post,
these results outline another very important fact: the <span class="caps">MAB</span> strategy generally
requires more samples to provide the exact same guarantees as A/B testing.
This means in particular that it would not be fair to compare click-through
rates at a single given sample size: that sample size should be adjusted separately
for each method in order to provide the same&nbsp;guarantees.</p>
<p>From my perspective, this is just like an insurance seller undermining the
competition by comparing the price of his most basic contract with the price 
of a broader contract (covering more stuff). 
Yes the basic contract is cheaper but this is comparing apples to
oranges. That said, that basic contract might very well be sufficient and this
is what I am going to assess in the next&nbsp;post.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>